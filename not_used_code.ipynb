{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter out values outside 0.03 and 0.97 percentile \n",
    "\n",
    "# def filter_by_percentile(df, lower_quantile=0.03, upper_quantile=0.97):\n",
    "#     for col in df.columns:\n",
    "#         if col == \"x\" or col == \"y\":\n",
    "#             continue\n",
    "#         # Calculate the quantiles for each column\n",
    "#         lower_bound = df[col].quantile(lower_quantile)\n",
    "#         upper_bound = df[col].quantile(upper_quantile)\n",
    "\n",
    "#         # Filter the DataFrame by the quantile range\n",
    "#         df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "#     return df\n",
    "\n",
    "# df = filter_by_percentile(df) ## Doesn't seem to work as is\n",
    "\n",
    "# def limit_by_percentile(df, lower_quantile=0.03, upper_quantile=0.97):\n",
    "#     for col in df.columns:\n",
    "#         if col == \"x\" or col == \"y\":\n",
    "#             continue\n",
    "\n",
    "#         # Calculate the quantiles for each column\n",
    "#         lower_bound = df[col].quantile(lower_quantile)\n",
    "#         upper_bound = df[col].quantile(upper_quantile)\n",
    "\n",
    "#         # Limit the DataFrame values by the quantile range\n",
    "#         df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "#     return df\n",
    "\n",
    "# df = limit_by_percentile(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for using GridSearchCV \n",
    "\n",
    "# x_train_data = []\n",
    "# y_train_data = []\n",
    "# for i in range(len(pos_train)):\n",
    "#     x_train_data.append(pos_train[i][0])\n",
    "#     y_train_data.append(pos_train[i][1])\n",
    "\n",
    "# param_grid = {\n",
    "#     #'n_estimators': [25],  # Number of trees in the forest\n",
    "#     'max_depth': [20, 30, 40],  # Maximum depth of the tree\n",
    "#     'min_samples_split':[2, 4, 6], # Minimum number of samples required to split an internal node\n",
    "#     'min_samples_leaf': [1, 2, 4], # Minimum number of samples required to be at a leaf node\n",
    "#     'max_features': [\"sqrt\", \"log2\", None]\n",
    "#     }\n",
    "\n",
    "# mult_regr_x = RandomForestRegressor(n_estimators=numb_trees, criterion=\"poisson\", random_state=42)\n",
    "# mult_regr_y = RandomForestRegressor(n_estimators=numb_trees, criterion=\"poisson\", random_state=42)\n",
    "\n",
    "\n",
    "# grid_search_x = GridSearchCV(\n",
    "#     estimator=mult_regr_x,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2)\n",
    "\n",
    "# grid_search_y = GridSearchCV(\n",
    "#     estimator=mult_regr_x,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=5,\n",
    "#     n_jobs=-1, \n",
    "#     verbose=2)\n",
    "\n",
    "# scaler = RobustScaler(quantile_range=(0.03, 0.97))\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     #('scaler', scaler),\n",
    "#     ('regressor', mult_regr),\n",
    "# ])\n",
    "\n",
    "# grid_search_x.fit(X_train, x_train_data)\n",
    "# grid_search_y.fit(X_train, y_train_data)\n",
    "\n",
    "# best_params_x = grid_search_x.best_params_\n",
    "# best_params_y = grid_search_y.best_params_\n",
    "\n",
    "#best_model = grid_search.best_estimator_\n",
    "#pos_pred = best_model.predict(X_val)\n",
    "\n",
    "# print(best_params_x)\n",
    "# print(best_params_y)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
